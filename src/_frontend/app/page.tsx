"use client"

import { useState, useRef, useEffect } from "react"
import { useTheme } from "@/hooks/useTheme"
import { ThemeToggle } from "@/components/ThemeToggle"

interface EmotionData {
  emotion: string
  percentage: number
  color: string
}

interface CapturedImage {
  id: number
  url: string
  analyzing: boolean
}

enum AnalysisMode {
  QUICK = "quick",
  DETAILED = "detailed"
}

// è‡ªå®šä¹‰Hookï¼šæ‰“å­—æœºæ•ˆæœ
function useTypewriter(text: string, baseSpeed: number = 50) {
  const [displayText, setDisplayText] = useState("")
  const [isTyping, setIsTyping] = useState(false)
  const [showCursor, setShowCursor] = useState(true)
  const [typingProgress, setTypingProgress] = useState(0) // 0-1 è¡¨ç¤ºæ‰“å­—è¿›åº¦

  useEffect(() => {
    if (!text) {
      setDisplayText("")
      setIsTyping(false)
      return
    }

    setIsTyping(true)
    setDisplayText("")
    let index = 0
    let animationId: number

    const typeNextChar = () => {
      if (index < text.length) {
        setDisplayText(prev => text.slice(0, index + 1)) // ä½¿ç”¨å‡½æ•°å¼æ›´æ–°
        setTypingProgress(index / text.length) // æ›´æ–°æ‰“å­—è¿›åº¦
        index++

        // è®¡ç®—ä¸‹ä¸€ä¸ªå­—ç¬¦çš„å»¶è¿Ÿæ—¶é—´
        let delay = baseSpeed
        const char = text[index - 1]

        // æ ¹æ®å­—ç¬¦ç±»å‹è°ƒæ•´é€Ÿåº¦
        if (char === '\n') {
          delay = baseSpeed * 1.5 // æ¢è¡Œåç¨å¾®åœé¡¿
        } else if (char === ' ') {
          delay = baseSpeed * 0.7 // ç©ºæ ¼æ‰“å¾—å¿«ä¸€äº›
        } else if (/[.!?]/.test(char)) {
          delay = baseSpeed * 2 // å¥å·ååœé¡¿æ›´ä¹…
        } else if (/[,;:]/.test(char)) {
          delay = baseSpeed * 1.2 // é€—å·åç¨å¾®åœé¡¿
        }

        // å‡å°‘éšæœºå˜åŒ–ï¼Œæé«˜ç¨³å®šæ€§
        delay += (Math.random() - 0.5) * baseSpeed * 0.2

        animationId = window.setTimeout(typeNextChar, Math.max(20, delay))
      } else {
        setIsTyping(false)
      }
    }

    // å¼€å§‹æ‰“å­—å‰ç¨å¾®å»¶è¿Ÿ
    animationId = window.setTimeout(typeNextChar, 200)

    return () => {
      if (animationId) {
        clearTimeout(animationId)
      }
    }
  }, [text, baseSpeed])

  // å…‰æ ‡é—ªçƒæ•ˆæœ - åªåœ¨æ‰“å­—æ—¶é—ªçƒ
  useEffect(() => {
    if (isTyping) {
      const cursorInterval = setInterval(() => {
        setShowCursor(prev => !prev)
      }, 500)
      return () => clearInterval(cursorInterval)
    } else {
      // æ‰“å­—å®Œæˆåéšè—å…‰æ ‡
      setShowCursor(false)
    }
  }, [isTyping])

  return { displayText, isTyping, showCursor, typingProgress }
}

export default function EmoscanApp() {
  const { isDark, mounted } = useTheme()
  const [isRecording, setIsRecording] = useState(false)
  const [isAnalyzing, setIsAnalyzing] = useState(false)
  const [analysisProgress, setAnalysisProgress] = useState(0)
  const [capturedImages, setCapturedImages] = useState<CapturedImage[]>([])
  const [emotionData, setEmotionData] = useState<EmotionData[]>([
    { emotion: "Happy", percentage: 0, color: "#00ff88" },
    { emotion: "Sad", percentage: 0, color: "#0099ff" },
    { emotion: "Angry", percentage: 0, color: "#ff0066" },
    { emotion: "Surprised", percentage: 0, color: "#ffaa00" },
    { emotion: "Neutral", percentage: 0, color: "#888888" },
    { emotion: "Disgusted", percentage: 0, color: "#9d4edd" },
    { emotion: "Fearful", percentage: 0, color: "#f72585" },
  ])
  const [llmOutput, setLlmOutput] = useState("")
  const [scanLine, setScanLine] = useState(0)
  const [currentTime, setCurrentTime] = useState("--:--:--") // é˜²æ­¢Hydrationä¸åŒ¹é…
  const [analysisMode, setAnalysisMode] = useState<AnalysisMode>(AnalysisMode.QUICK)

  // ä½¿ç”¨æ‰“å­—æœºæ•ˆæœ
  const { displayText, isTyping, showCursor, typingProgress } = useTypewriter(llmOutput, 25)

  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const outputRef = useRef<HTMLDivElement>(null)

  // é˜²æ­¢é‡å¤APIè°ƒç”¨çš„é”å®šæœºåˆ¶
  const apiCallLockRef = useRef<boolean>(false)
  const currentCallIdRef = useRef<string | null>(null)

  // è‡ªåŠ¨æ»šåŠ¨é€»è¾‘
  useEffect(() => {
    if (outputRef.current) {
      if (isTyping) {
        // æ‰“å­—æ—¶æ»šåŠ¨åˆ°åº•éƒ¨
        outputRef.current.scrollTop = outputRef.current.scrollHeight
      } else if (displayText && !isTyping) {
        // æ‰“å­—å®Œæˆåï¼Œç¼“æ…¢æ»šåŠ¨åˆ°é¡¶éƒ¨
        const scrollToTop = () => {
          const element = outputRef.current
          if (element) {
            const startScrollTop = element.scrollTop
            const duration = 2000 // 2ç§’æ»šåŠ¨åˆ°é¡¶éƒ¨
            const startTime = performance.now()

            const animateScroll = (currentTime: number) => {
              const elapsed = currentTime - startTime
              const progress = Math.min(elapsed / duration, 1)

              // ä½¿ç”¨easeInOutCubicç¼“åŠ¨å‡½æ•°
              const easeProgress = progress < 0.5
                ? 4 * progress * progress * progress
                : 1 - Math.pow(-2 * progress + 2, 3) / 2

              element.scrollTop = startScrollTop * (1 - easeProgress)

              if (progress < 1) {
                requestAnimationFrame(animateScroll)
              }
            }

            requestAnimationFrame(animateScroll)
          }
        }

        // å»¶è¿Ÿ1ç§’åå¼€å§‹æ»šåŠ¨
        const timer = setTimeout(scrollToTop, 1000)
        return () => clearTimeout(timer)
      }
    }
  }, [displayText, isTyping])

  // æ‰«æçº¿åŠ¨ç”»
  useEffect(() => {
    const interval = setInterval(() => {
      setScanLine((prev) => (prev + 1) % 100)
    }, 50)
    return () => clearInterval(interval)
  }, [])

  // æ—¶é—´æ›´æ–° - é˜²æ­¢Hydrationä¸åŒ¹é…
  useEffect(() => {
    // åªåœ¨å®¢æˆ·ç«¯æŒ‚è½½åæ‰å¼€å§‹æ›´æ–°æ—¶é—´
    if (!mounted) return

    const updateTime = () => {
      setCurrentTime(new Date().toLocaleTimeString())
    }

    // ç«‹å³æ›´æ–°ä¸€æ¬¡
    updateTime()

    // æ¯ç§’æ›´æ–°
    const interval = setInterval(updateTime, 1000)
    return () => clearInterval(interval)
  }, [mounted])

  // éšè—æ»šåŠ¨æ¡å’Œæ·»åŠ æ–‡å­—å¤§å°æ¸å˜æ•ˆæœ + æ— é™å¾ªç¯æ»šåŠ¨
  useEffect(() => {
    if (outputRef.current) {
      const element = outputRef.current
      // ç›´æ¥è®¾ç½®CSSæ ·å¼æ¥éšè—æ»šåŠ¨æ¡
      element.style.setProperty('scrollbar-width', 'none', 'important')
      element.style.setProperty('-ms-overflow-style', 'none', 'important')

      // åˆ›å»ºæ ·å¼è§„åˆ™
      const style = document.createElement('style')
      style.textContent = `
        .ai-output-container::-webkit-scrollbar {
          display: none !important;
          width: 0 !important;
          height: 0 !important;
        }

        /* 3Dåœ†æŸ±ä½“é€è§†æ–‡å­—å®¹å™¨ */
        .cylindrical-text-container {
          position: relative;
          perspective: 1200px;
          transform-style: preserve-3d;
          overflow: hidden;
        }

        /* æ¯è¡Œæ–‡å­—çš„åŸºç¡€æ ·å¼ */
        .text-line {
          display: block;
          text-align: center;
          font-family: 'Courier New', monospace;
          white-space: pre-wrap;
          transition: all 0.08s ease-out;
          transform-origin: center center;
        }

        /* æ»šåŠ¨å®¹å™¨ä¼˜åŒ– */
        .ai-output-container {
          scroll-behavior: smooth; /* æ¢å¤å¹³æ»‘æ»šåŠ¨ */
          will-change: scroll-position;
          -webkit-overflow-scrolling: touch;
          /* ç¡®ä¿å¯ä»¥æ­£å¸¸é€‰æ‹©æ–‡æœ¬ */
          user-select: text;
          -webkit-user-select: text;
          -moz-user-select: text;
          -ms-user-select: text;
          /* ç¡®ä¿æ»šåŠ¨æ­£å¸¸å·¥ä½œ */
          overflow-y: auto;
          overflow-x: hidden;
        }

        /* ç§»é™¤é˜»æ­¢æ»šåŠ¨çš„ä¼ªå…ƒç´  */
      `
      document.head.appendChild(style)

      // 3Dåœ†æŸ±ä½“æ•ˆæœçš„æ»šåŠ¨ç›‘å¬å™¨ - ä¼˜åŒ–æ€§èƒ½å’Œå¹³æ»‘åº¦
      let animationId: number

      const handleScroll = () => {
        // ä½¿ç”¨requestAnimationFrameä¼˜åŒ–æ€§èƒ½
        if (animationId) {
          cancelAnimationFrame(animationId)
        }

        animationId = requestAnimationFrame(() => {
          const textLines = element.querySelectorAll('.text-line') as NodeListOf<HTMLElement>
          if (textLines.length === 0) return

          const containerRect = element.getBoundingClientRect()
          const containerHeight = containerRect.height
          const containerCenter = containerHeight / 2

          // ä¸ºæ¯ä¸€è¡Œæ–‡å­—è®¡ç®—é€è§†æ•ˆæœ
          textLines.forEach((line) => {
            const lineRect = line.getBoundingClientRect()
            const lineCenter = lineRect.top + lineRect.height / 2 - containerRect.top

            // è®¡ç®—è·ç¦»å®¹å™¨ä¸­å¿ƒçš„è·ç¦» (0-1, 0ä¸ºä¸­å¿ƒ)
            const distanceFromCenter = Math.abs(lineCenter - containerCenter) / containerCenter

            // é™åˆ¶è·ç¦»èŒƒå›´ï¼Œä½¿ç”¨æ›´å¹³æ»‘çš„æ›²çº¿
            const clampedDistance = Math.min(distanceFromCenter, 1)
            const smoothDistance = Math.pow(clampedDistance, 0.8) // ä½¿ç”¨å¹‚å‡½æ•°åˆ›å»ºæ›´å¹³æ»‘çš„è¿‡æ¸¡

            // è®¡ç®—é€è§†æ•ˆæœå‚æ•° - è°ƒæ•´ä¸ºæ›´æ¸©å’Œçš„å˜åŒ–
            // å­—ä½“å¤§å°ï¼šä¸­å¿ƒæœ€å¤§(16px)ï¼Œè¾¹ç¼˜æœ€å°(11px)
            const fontSize = 16 - (smoothDistance * 5)

            // é€æ˜åº¦ï¼šä¸­å¿ƒæœ€äº®(1.0)ï¼Œè¾¹ç¼˜æœ€æš—(0.4) - ç¡®ä¿è¾¹ç¼˜æ–‡å­—ä»ç„¶å¯è§
            const opacity = 1.0 - (smoothDistance * 0.6)

            // å®½åº¦ï¼šä¸­å¿ƒæœ€å®½(100%)ï¼Œè¾¹ç¼˜æœ€çª„(75%)
            const width = 100 - (smoothDistance * 25)

            // Zè½´ä½ç§»ï¼šåˆ›å»ºæ·±åº¦æ•ˆæœ
            const translateZ = -smoothDistance * 25

            // Xè½´æ—‹è½¬ï¼šå¢å¼ºé€è§†æ•ˆæœ
            const rotateX = smoothDistance * 6

            // åº”ç”¨æ ·å¼
            line.style.fontSize = `${fontSize}px`
            line.style.opacity = `${opacity}`
            line.style.width = `${width}%`
            line.style.margin = '0 auto'
            line.style.transform = `translateZ(${translateZ}px) rotateX(${rotateX}deg)`

            // ä½¿ç”¨CSSå˜é‡è·å–å½“å‰ä¸»é¢˜çš„æ–‡æœ¬é¢œè‰²
            const rootStyles = window.getComputedStyle(document.documentElement)
            const textColorHsl = rootStyles.getPropertyValue('--emoscan-text').trim()
            const accentColorHsl = rootStyles.getPropertyValue('--emoscan-accent').trim()

            // å°†HSLè½¬æ¢ä¸ºRGBä»¥ä¾¿è®¾ç½®é€æ˜åº¦
            const isDarkTheme = document.documentElement.classList.contains('dark')
            if (isDarkTheme) {
              // æ·±è‰²ä¸»é¢˜ï¼šä½¿ç”¨ç»¿è‰²ç³»
              line.style.color = `hsla(${accentColorHsl}, ${opacity})`
              line.style.textShadow = `0 0 ${12 * opacity}px hsla(${accentColorHsl}, ${opacity * 0.5}),
                 0 ${1.5 * opacity}px ${6 * opacity}px rgba(0,0,0,0.3),
                 0 0 ${25 * opacity}px hsla(${accentColorHsl}, ${opacity * 0.25})`
            } else {
              // æµ…è‰²ä¸»é¢˜ï¼šä½¿ç”¨æ·±è‰²æ–‡å­—
              line.style.color = `hsla(${textColorHsl}, ${opacity})`
              line.style.textShadow = `0 ${1 * opacity}px ${3 * opacity}px rgba(0,0,0,0.2)`
            }
          })
        })
      }

      // æ»šåŠ¨å¤„ç†å˜é‡ï¼ˆä¿ç•™ç”¨äºæ¸…ç†ï¼‰

      // åˆå§‹åŒ–æ–‡æœ¬è¡Œæ ·å¼
      const initializeTextLines = () => {
        // å»¶è¿Ÿæ‰§è¡Œï¼Œç¡®ä¿DOMå·²æ›´æ–°
        setTimeout(() => {
          handleScroll()
        }, 50)
      }

      // åªæ·»åŠ æ»šåŠ¨ç›‘å¬å™¨ï¼Œç§»é™¤wheelç›‘å¬å™¨è®©æµè§ˆå™¨å¤„ç†æ»šè½®äº‹ä»¶
      element.addEventListener('scroll', handleScroll, { passive: true })

      // é˜²æ­¢æ–‡æœ¬é€‰æ‹©æ—¶çš„æ„å¤–æ»šåŠ¨
      element.addEventListener('selectstart', (e) => {
        // å…è®¸æ–‡æœ¬é€‰æ‹©ï¼Œä½†é˜²æ­¢é€‰æ‹©æ—¶çš„æ»šåŠ¨
        e.stopPropagation()
      }, { passive: true })

      element.addEventListener('mousedown', (e) => {
        // å¦‚æœæ˜¯æ–‡æœ¬é€‰æ‹©æ“ä½œï¼Œä¸è§¦å‘æ»šåŠ¨
        if (e.detail > 1) { // åŒå‡»æˆ–å¤šå‡»
          e.stopPropagation()
        }
      }, { passive: true })

      // ç›‘å¬DOMå˜åŒ–ï¼Œå½“æ–‡æœ¬å†…å®¹æ›´æ–°æ—¶é‡æ–°è®¡ç®—æ ·å¼
      const observer = new MutationObserver(() => {
        initializeTextLines()
      })

      observer.observe(element, {
        childList: true,
        subtree: true,
        characterData: true
      })

      // åˆå§‹åŒ–
      initializeTextLines()

      return () => {
        element.removeEventListener('scroll', handleScroll)
        observer.disconnect()
        document.head.removeChild(style)

        // æ¸…ç†åŠ¨ç”»å¸§
        if (animationId) {
          cancelAnimationFrame(animationId)
        }
      }
    }
  }, [])

  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop())
      }
    }
  }, [])

  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 480 },
      })
      streamRef.current = stream
      if (videoRef.current) {
        videoRef.current.srcObject = stream
      }
    } catch (error) {
      console.error("Error accessing camera:", error)
    }
  }

  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop())
      streamRef.current = null
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null
    }
  }

  const captureImage = () => {
    if (videoRef.current && canvasRef.current) {
      const canvas = canvasRef.current
      const video = videoRef.current
      canvas.width = video.videoWidth
      canvas.height = video.videoHeight

      const ctx = canvas.getContext("2d")
      if (ctx) {
        ctx.drawImage(video, 0, 0)
        return canvas.toDataURL("image/jpeg")
      }
    }
    return null
  }

  const startRecording = async () => {
    setIsRecording(true)
    setCapturedImages([])
    setAnalysisProgress(0)
    setLlmOutput("")

    await startCamera()

    const captureInterval = setInterval(() => {
      const imageUrl = captureImage()
      if (imageUrl) {
        setCapturedImages((prev) => {
          const newImage = {
            id: prev.length + 1,
            url: imageUrl,
            analyzing: true,
          }
          const updated = [...prev, newImage]

          if (updated.length >= 5) {
            clearInterval(captureInterval)
            startAnalysis(updated)
          }

          return updated
        })
      }
    }, 800)
  }

  const startAnalysis = async (images: CapturedImage[]) => {
    const callId = Math.random().toString(36).substr(2, 9);
    setIsRecording(false)
    setIsAnalyzing(true)
    stopCamera()

    // æ ¹æ®åˆ†ææ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼
    if (analysisMode === AnalysisMode.DETAILED) {
      // è¯¦ç»†æ¨¡å¼ï¼šåˆ†ææ‰€æœ‰å›¾åƒ
      await analyzeBatchImages(images)
      return // è¯¦ç»†æ¨¡å¼å®Œæˆåç›´æ¥è¿”å›
    } else {
      // å¿«é€Ÿæ¨¡å¼ï¼šåªåˆ†ææœ€åä¸€å¼ å›¾åƒ
      if (images.length > 0) {
        const lastImage = images[images.length - 1]

        // å°†dataURLè½¬æ¢ä¸ºBlob
        if (lastImage.url) {
          try {
            const response = await fetch(lastImage.url)
            const blob = await response.blob()

            // è°ƒç”¨åç«¯API
            await analyzeImageWithAPI(blob, callId)
            setIsAnalyzing(false)

            // æ›´æ–°å›¾åƒçŠ¶æ€
            images.forEach((_, index) => {
              setTimeout(
                () => {
                  setCapturedImages((prev) => prev.map((img, i) => (i === index ? { ...img, analyzing: false } : img)))
                },
                (index + 1) * 200,
              )
            })

            return // å¿«é€Ÿæ¨¡å¼APIè°ƒç”¨æˆåŠŸåç›´æ¥è¿”å›
          } catch (error) {
            console.error('å¿«é€Ÿæ¨¡å¼å›¾åƒè½¬æ¢å¤±è´¥:', error)
            // å¿«é€Ÿæ¨¡å¼å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œfallbacké€»è¾‘
          }
        }
      }
    }

    // åªæœ‰åœ¨å¿«é€Ÿæ¨¡å¼å¤±è´¥æ—¶æ‰æ‰§è¡Œfallbacké€»è¾‘
    console.log('æ‰§è¡Œfallbacké€»è¾‘ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®')
    let progress = 0
    const progressInterval = setInterval(() => {
      progress += Math.random() * 15
      if (progress >= 100) {
        progress = 100
        clearInterval(progressInterval)
        completeAnalysisWithMockData()
        setIsAnalyzing(false)
      }
      setAnalysisProgress(progress)
    }, 200)

    images.forEach((_, index) => {
      setTimeout(
        () => {
          setCapturedImages((prev) => prev.map((img, i) => (i === index ? { ...img, analyzing: false } : img)))
        },
        (index + 1) * 1000,
      )
    })
  }

  // æ‰¹é‡åˆ†ææ‰€æœ‰å›¾åƒ
  const analyzeBatchImages = async (images: CapturedImage[]) => {
    try {
      // é¦–å…ˆæ£€æŸ¥APIæ˜¯å¦å¯ç”¨
      const apiAvailable = await checkApiAvailability();
      
      if (!apiAvailable) {
        // APIä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        console.log("APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®");
        completeAnalysisWithMockData();
        setIsAnalyzing(false);
        
        // æ›´æ–°å›¾åƒçŠ¶æ€
        images.forEach((_, index) => {
          setTimeout(
            () => {
              setCapturedImages((prev) => prev.map((img, i) => (i === index ? { ...img, analyzing: false } : img)))
            },
            (index + 1) * 200,
          )
        });
        return;
      }
      
      const formData = new FormData()

      // å°†æ‰€æœ‰å›¾åƒè½¬æ¢ä¸ºBlobå¹¶æ·»åŠ åˆ°FormData
      for (let i = 0; i < images.length; i++) {
        const image = images[i]
        if (image.url) {
          const response = await fetch(image.url)
          const blob = await response.blob()
          formData.append('files', blob, `capture_${i+1}.jpg`)
        }
      }

      // å¯¹äºæ‰¹é‡åˆ†æï¼Œæˆ‘ä»¬å…ˆä½¿ç”¨åŸæœ‰çš„æ‰¹é‡APIï¼Œç„¶ååŸºäºç»“æœç”Ÿæˆå›¾åƒ
      const response = await fetch('http://localhost:8000/api/v1/analyze/batch', {
        method: 'POST',
        body: formData,
      })

      if (!response.ok) {
        throw new Error(`æ‰¹é‡APIè°ƒç”¨å¤±è´¥: ${response.status}`)
      }

      const result = await response.json()

      if (result.success) {
        // ä½¿ç”¨APIè¿”å›çš„æƒ…ç»ªæ•°æ®
        setEmotionData(result.emotion_data)

        // ä½¿ç”¨APIè¿”å›çš„åˆ†ææ–‡æœ¬
        let analysisText = result.analysis_text

        // å°è¯•åŸºäºæ‰¹é‡åˆ†æç»“æœç”Ÿæˆå›¾åƒ
        try {
          const imageGenResponse = await fetch('http://localhost:8000/api/v1/generation/generate-from-analysis', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              emotion_data: result.emotion_data,
              seed: Math.floor(Math.random() * 1000000) // éšæœºç§å­
            }),
          })

          if (imageGenResponse.ok) {
            const imageGenResult = await imageGenResponse.json()

            // æ·»åŠ å›¾åƒç”Ÿæˆç»“æœä¿¡æ¯
            analysisText += "\n\n" + "â”".repeat(80) + "\n"
            analysisText += ">>> COMFYUI IMAGE GENERATION <<<\n\n"

            if (imageGenResult.success) {
              analysisText += `âœ… å›¾åƒç”ŸæˆæˆåŠŸ!\n`
              analysisText += `ğŸ¨ ç”Ÿæˆæ—¶é—´: ${imageGenResult.generation_time?.toFixed(2)}ç§’\n`
              analysisText += `ğŸ“¸ ç”Ÿæˆå›¾åƒ: ${imageGenResult.images?.length || 0}å¼ \n`

              if (imageGenResult.images && imageGenResult.images.length > 0) {
                analysisText += `\nç”Ÿæˆçš„å›¾åƒ:\n`
                imageGenResult.images.forEach((img: any, index: number) => {
                  analysisText += `${index + 1}. ${img.filename}\n`
                  analysisText += `   URL: ${img.url}\n`
                })
              }
            } else {
              analysisText += `âŒ å›¾åƒç”Ÿæˆå¤±è´¥: ${imageGenResult.error_message}\n`
              analysisText += `ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n`
            }
          } else {
            analysisText += "\n\n" + "â”".repeat(80) + "\n"
            analysisText += ">>> COMFYUI IMAGE GENERATION <<<\n\n"
            analysisText += `âŒ å›¾åƒç”ŸæˆAPIè°ƒç”¨å¤±è´¥: ${imageGenResponse.status}\n`
          }
        } catch (imageGenError) {
          console.warn('å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œä½†æƒ…ç»ªåˆ†ææˆåŠŸ:', imageGenError)
          analysisText += "\n\n" + "â”".repeat(80) + "\n"
          analysisText += ">>> COMFYUI IMAGE GENERATION <<<\n\n"
          analysisText += `âŒ å›¾åƒç”Ÿæˆå¼‚å¸¸: ${imageGenError}\n`
        }

        setLlmOutput(analysisText)
      } else {
        // APIè°ƒç”¨å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        const errorText = `>>> æ‰¹é‡APIè°ƒç”¨å¤±è´¥ <<<\n\né”™è¯¯ä¿¡æ¯: ${result.error_message || 'æœªçŸ¥é”™è¯¯'}\n\nè¯·æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚`
        setLlmOutput(errorText)

        // ä½¿ç”¨é»˜è®¤çš„æƒ…ç»ªæ•°æ®
        completeAnalysisWithMockData()
      }

      setIsAnalyzing(false)

      // æ›´æ–°å›¾åƒçŠ¶æ€
      images.forEach((_, index) => {
        setTimeout(
          () => {
            setCapturedImages((prev) => prev.map((img, i) => (i === index ? { ...img, analyzing: false } : img)))
          },
          (index + 1) * 200,
        )
      })

    } catch (error) {
      console.error('æ‰¹é‡APIè°ƒç”¨å¼‚å¸¸:', error)

      // ç½‘ç»œé”™è¯¯æˆ–å…¶ä»–å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å¹¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      const errorText = `>>> æ‰¹é‡åˆ†æè¿æ¥å¤±è´¥ <<<\n\né”™è¯¯ä¿¡æ¯: ${error}\n\næ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...`
      setLlmOutput(errorText)

      // ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      completeAnalysisWithMockData()
      setIsAnalyzing(false)

      // æ›´æ–°å›¾åƒçŠ¶æ€
      images.forEach((_, index) => {
        setTimeout(
          () => {
            setCapturedImages((prev) => prev.map((img, i) => (i === index ? { ...img, analyzing: false } : img)))
          },
          (index + 1) * 200,
        )
      })
    }
  }

  // æ£€æŸ¥APIæ˜¯å¦å¯ç”¨
  const checkApiAvailability = async () => {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 2000); // 2ç§’è¶…æ—¶
      
      const response = await fetch('http://localhost:8000/health', {
        method: 'GET',
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      return response.ok;
    } catch (error) {
      console.log('APIä¸å¯ç”¨:', error);
      return false;
    }
  };

  // è°ƒç”¨åç«¯APIè¿›è¡Œæƒ…ç»ªåˆ†æå’Œå›¾åƒç”Ÿæˆ
  const analyzeImageWithAPI = async (imageBlob: Blob, callId?: string) => {
    const id = callId || Math.random().toString(36).substr(2, 9);

    // é˜²æ­¢é‡å¤è°ƒç”¨
    if (apiCallLockRef.current) {
      console.warn(`APIè°ƒç”¨è¢«é˜»æ­¢ï¼Œå·²æœ‰è°ƒç”¨æ­£åœ¨è¿›è¡Œä¸­: ${currentCallIdRef.current}`);
      return;
    }

    // è®¾ç½®é”å®š
    apiCallLockRef.current = true;
    currentCallIdRef.current = id;

    try {
      // é¦–å…ˆæ£€æŸ¥APIæ˜¯å¦å¯ç”¨
      const apiAvailable = await checkApiAvailability();

      if (!apiAvailable) {
        // APIä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        console.log("APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®");
        completeAnalysisWithMockData();
        return;
      }

      const formData = new FormData()
      formData.append('file', imageBlob, 'capture.jpg')

      // ç¬¬ä¸€æ­¥ï¼šè¿›è¡Œæƒ…ç»ªåˆ†æ
      const response = await fetch('http://localhost:8000/api/v1/analyze/image', {
        method: 'POST',
        body: formData,
      })

      if (!response.ok) {
        throw new Error(`APIè°ƒç”¨å¤±è´¥: ${response.status}`)
      }

      const result = await response.json()

      if (result.success) {
        // ä½¿ç”¨APIè¿”å›çš„æƒ…ç»ªæ•°æ®
        setEmotionData(result.emotion_data)

        // ä½¿ç”¨APIè¿”å›çš„åˆ†ææ–‡æœ¬
        let analysisText = result.analysis_text

        // ç¬¬äºŒæ­¥ï¼šåŸºäºæƒ…ç»ªåˆ†æç»“æœç”Ÿæˆå›¾åƒ
        try {
          const imageGenResponse = await fetch('http://localhost:8000/api/v1/generation/generate-from-analysis', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              emotion_data: result.emotion_data,
              seed: Math.floor(Math.random() * 1000000) // éšæœºç§å­
            }),
          })

          // æ·»åŠ å›¾åƒç”Ÿæˆç»“æœä¿¡æ¯
          analysisText += "\n\n" + "â”".repeat(80) + "\n"
          analysisText += ">>> COMFYUI IMAGE GENERATION <<<\n\n"

          if (imageGenResponse.ok) {
            const imageGenResult = await imageGenResponse.json()

            if (imageGenResult.success) {
              analysisText += `âœ… å›¾åƒç”ŸæˆæˆåŠŸ!\n`
              analysisText += `ğŸ¨ ç”Ÿæˆæ—¶é—´: ${imageGenResult.generation_time?.toFixed(2)}ç§’\n`
              analysisText += `ğŸ“¸ ç”Ÿæˆå›¾åƒ: ${imageGenResult.images?.length || 0}å¼ \n`

              if (imageGenResult.images && imageGenResult.images.length > 0) {
                analysisText += `\nç”Ÿæˆçš„å›¾åƒ:\n`
                imageGenResult.images.forEach((img: any, index: number) => {
                  analysisText += `${index + 1}. ${img.filename}\n`
                  analysisText += `   URL: ${img.url}\n`
                })
              }
            } else {
              analysisText += `âŒ å›¾åƒç”Ÿæˆå¤±è´¥: ${imageGenResult.error_message}\n`
              analysisText += `ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n`
            }
          } else {
            analysisText += `âŒ å›¾åƒç”ŸæˆAPIè°ƒç”¨å¤±è´¥: ${imageGenResponse.status}\n`
          }
        } catch (imageGenError) {
          console.warn('å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œä½†æƒ…ç»ªåˆ†ææˆåŠŸ:', imageGenError)
          analysisText += `âŒ å›¾åƒç”Ÿæˆå¼‚å¸¸: ${imageGenError}\n`
        }

        setLlmOutput(analysisText)
      } else {
        // APIè°ƒç”¨å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        const errorText = `>>> APIè°ƒç”¨å¤±è´¥ <<<\n\né”™è¯¯ä¿¡æ¯: ${result.error_message || 'æœªçŸ¥é”™è¯¯'}\n\nè¯·æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚`
        setLlmOutput(errorText)

        // ä½¿ç”¨é»˜è®¤çš„æƒ…ç»ªæ•°æ®
        completeAnalysisWithMockData()
      }
    } catch (error) {
      console.error('APIè°ƒç”¨å¼‚å¸¸:', error)

      // ç½‘ç»œé”™è¯¯æˆ–å…¶ä»–å¼‚å¸¸ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å¹¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      const errorText = `>>> ç½‘ç»œè¿æ¥å¤±è´¥ <<<\n\né”™è¯¯ä¿¡æ¯: ${error}\n\næ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...`
      setLlmOutput(errorText)

      // ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      completeAnalysisWithMockData()
    } finally {
      // é‡Šæ”¾é”å®š
      apiCallLockRef.current = false;
      currentCallIdRef.current = null;
    }
  }

  const completeAnalysisWithMockData = () => {
    const newEmotionData = [
      { emotion: "Happy", percentage: Math.random() * 40 + 30, color: "#00ff88" },
      { emotion: "Sad", percentage: Math.random() * 20 + 5, color: "#0099ff" },
      { emotion: "Angry", percentage: Math.random() * 15 + 5, color: "#ff0066" },
      { emotion: "Surprised", percentage: Math.random() * 20 + 10, color: "#ffaa00" },
      { emotion: "Neutral", percentage: Math.random() * 25 + 15, color: "#888888" },
      { emotion: "Disgusted", percentage: Math.random() * 10 + 2, color: "#9d4edd" },
      { emotion: "Fearful", percentage: Math.random() * 15 + 3, color: "#f72585" },
    ]

    setEmotionData(newEmotionData)

    const analysisText = [
      ">>> NEURAL NETWORK ANALYSIS COMPLETE <<<",
      "",
      "EMOTIONAL SIGNATURE DETECTED:",
      "â”".repeat(80),
      "",
      "SUBJECT ANALYSIS:",
      `â€¢ Primary Emotion: ${newEmotionData[0].emotion.toUpperCase()}`,
      `â€¢ Confidence Level: ${Math.floor(newEmotionData[0].percentage)}%`,
      `â€¢ Secondary Traits: ${newEmotionData
        .slice(1, 3)
        .map((e) => e.emotion)
        .join(", ")}`,
      "",
      "BIOMETRIC DATA:",
      "â€¢ Heart Rate Variability: DETECTED",
      "â€¢ Micro-expressions: 47 PATTERNS IDENTIFIED",
      "â€¢ Facial Symmetry: ANALYZED",
      "â€¢ Eye Movement: TRACKED",
      "",
      "PSYCHOLOGICAL PROFILE:",
      "â€¢ Stress Indicators: LOW-MODERATE",
      "â€¢ Authenticity Score: 87.3%",
      "â€¢ Emotional Stability: STABLE",
      "â€¢ Cognitive Load: NORMAL",
      "",
      "RECOMMENDATION:",
      "Subject displays genuine emotional responses.",
      "No deception indicators detected.",
      "Emotional state within normal parameters.",
      "",
      "â”".repeat(80),
      "ANALYSIS TIMESTAMP: " + currentTime,
      "NEURAL NETWORK VERSION: EMOSCAN v2.1.7",
      "STATUS: COMPLETE",
    ].join("\n")

    setLlmOutput(analysisText)
  }

  return (
    <div className="min-h-screen font-mono overflow-hidden relative transition-colors duration-300 bg-[hsl(var(--emoscan-bg))] text-[hsl(var(--emoscan-text))]">
      {/* èƒŒæ™¯ç½‘æ ¼ */}
      <div className="absolute inset-0 opacity-10">
        <div className="grid grid-cols-20 grid-rows-20 h-full w-full">
          {Array.from({ length: 400 }).map((_, i) => (
            <div key={i} className="border border-[hsl(var(--emoscan-grid)/0.2)]" />
          ))}
        </div>
      </div>

      {/* é¡¶éƒ¨å¯¼èˆªæ  */}
      <header className="relative z-10 border-b backdrop-blur-sm transition-colors duration-300 border-[hsl(var(--emoscan-border)/0.3)] bg-[hsl(var(--emoscan-bg)/0.8)]">
        <div className="flex items-center justify-between px-6 py-4">
          <div className="flex items-center space-x-4">
            <div className="text-2xl font-bold animate-pulse text-[hsl(var(--emoscan-accent))]">EMOSCAN</div>
            <div className="text-sm text-[hsl(var(--emoscan-text)/0.7)]">Neural Emotion Analysis System</div>
          </div>
          <div className="flex items-center space-x-4">
            <div className="flex items-center space-x-2">
              <div className="w-2 h-2 rounded-full animate-pulse bg-[hsl(var(--emoscan-accent))]" />
              <span className="text-xs">SYSTEM ONLINE</span>
            </div>
            <div className="text-xs text-[hsl(var(--emoscan-text)/0.7)]">{currentTime}</div>
            {/* ä¸»é¢˜åˆ‡æ¢æŒ‰é’® */}
            <ThemeToggle />
          </div>
        </div>
      </header>

      {/* ä¸»è¦å†…å®¹åŒºåŸŸ */}
      <div className="flex h-[calc(100vh-80px)] relative z-10">
        {/* å·¦ä¾§é¢æ¿ - æ‘„åƒå¤´åŒºåŸŸ */}
        <div className="w-1/3 border-r backdrop-blur-sm p-6 transition-colors duration-300 border-[hsl(var(--emoscan-border)/0.3)] bg-[hsl(var(--emoscan-panel)/0.5)]">
          <div className="h-full flex flex-col">
            <h2 className="text-lg font-semibold mb-4 text-[hsl(var(--emoscan-accent))]">VISUAL INPUT</h2>

            {/* æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ */}
            <div className="flex-1 relative border rounded-lg overflow-hidden transition-colors duration-300 border-[hsl(var(--emoscan-border)/0.5)] bg-[hsl(var(--emoscan-bg)/0.8)]">
              <video
                ref={videoRef}
                autoPlay
                muted
                className="w-full h-full object-cover"
                style={{ transform: "scaleX(-1)" }}
              />
              <canvas ref={canvasRef} className="hidden" />

              {/* æ‰«æçº¿æ•ˆæœ */}
              {isRecording && (
                <div
                  className="absolute left-0 w-full h-0.5 shadow-lg bg-[hsl(var(--emoscan-accent))] shadow-[hsl(var(--emoscan-accent)/0.5)]"
                  style={{
                    top: `${scanLine}%`,
                    transition: "top 0.05s linear",
                  }}
                />
              )}

              {/* å½•åˆ¶çŠ¶æ€æŒ‡ç¤ºå™¨ */}
              {isRecording && (
                <div className="absolute top-4 left-4 flex items-center space-x-2">
                  <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
                  <span className="text-sm text-red-400">RECORDING</span>
                </div>
              )}
            </div>

            {/* æ§åˆ¶æŒ‰é’® */}
            <div className="mt-4 space-y-3">
              {/* åˆ†ææ¨¡å¼åˆ‡æ¢ */}
              <div className="grid grid-cols-2 gap-2">
                <button
                  onClick={() => setAnalysisMode(AnalysisMode.QUICK)}
                  className={`py-2 px-3 border rounded-lg text-xs transition-all duration-200 ${
                    analysisMode === AnalysisMode.QUICK
                      ? 'bg-blue-600/30 border-blue-400/50 text-blue-400 shadow-lg shadow-blue-400/20'
                      : 'bg-gray-600/20 border-gray-400/50 text-gray-400 hover:bg-gray-600/30'
                  }`}
                >
                  ğŸš€ QUICK MODE
                </button>
                <button
                  onClick={() => setAnalysisMode(AnalysisMode.DETAILED)}
                  className={`py-2 px-3 border rounded-lg text-xs transition-all duration-200 ${
                    analysisMode === AnalysisMode.DETAILED
                      ? 'bg-orange-600/30 border-orange-400/50 text-orange-400 shadow-lg shadow-orange-400/20'
                      : 'bg-gray-600/20 border-gray-400/50 text-gray-400 hover:bg-gray-600/30'
                  }`}
                >
                  ğŸ” DETAILED MODE
                </button>
              </div>

              {/* æ¨¡å¼è¯´æ˜ */}
              <div className="text-xs text-gray-400 text-center">
                {analysisMode === AnalysisMode.QUICK
                  ? "å¿«é€Ÿæ¨¡å¼ï¼šåˆ†ææœ€å1å¼ å›¾ç‰‡ (~5ç§’)"
                  : "è¯¦ç»†æ¨¡å¼ï¼šåˆ†æå…¨éƒ¨5å¼ å›¾ç‰‡ + è£åˆ¤å‘˜AI (~20ç§’)"}
              </div>

              <button
                onClick={startRecording}
                disabled={isRecording || isAnalyzing}
                className="w-full py-3 px-4 bg-green-600/20 border border-green-400/50 rounded-lg text-green-400 hover:bg-green-600/30 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200 hover:shadow-lg hover:shadow-green-400/20"
              >
                {isRecording ? "CAPTURING..." : `START SCAN (${analysisMode.toUpperCase()})`}
              </button>









              {/* æ•è·çš„å›¾åƒé¢„è§ˆ */}
              {capturedImages.length > 0 && (
                <div className="grid grid-cols-5 gap-2">
                  {capturedImages.map((img) => (
                    <div key={img.id} className="relative">
                      <img
                        src={img.url || "/placeholder.svg"}
                        alt={`Capture ${img.id}`}
                        className="w-full h-12 object-cover rounded border border-green-400/30"
                      />
                      {img.analyzing && <div className="absolute inset-0 bg-cyan-400/20 animate-pulse rounded" />}
                    </div>
                  ))}
                </div>
              )}
            </div>
          </div>
        </div>

        {/* ä¸­é—´é¢æ¿ - æƒ…æ„Ÿåˆ†æ */}
        <div className="w-1/3 border-r backdrop-blur-sm p-6 transition-colors duration-300 border-[hsl(var(--emoscan-border)/0.3)] bg-[hsl(var(--emoscan-panel)/0.5)]">
          <div className="h-full flex flex-col">
            <h2 className="text-lg font-semibold mb-4 text-[hsl(var(--emoscan-accent))]">EMOTION ANALYSIS</h2>

            {/* åˆ†æè¿›åº¦ */}
            {isAnalyzing && (
              <div className="mb-6">
                <div className="flex justify-between text-sm mb-2">
                  <span>Processing...</span>
                  <span>{Math.floor(analysisProgress)}%</span>
                </div>
                <div className="w-full rounded-full h-2 bg-[hsl(var(--muted))]">
                  <div
                    className="h-2 rounded-full transition-all duration-200 bg-gradient-to-r from-[hsl(var(--emoscan-accent))] to-[hsl(var(--emoscan-accent))]"
                    style={{ width: `${analysisProgress}%` }}
                  />
                </div>
              </div>
            )}

            {/* æƒ…æ„Ÿæ•°æ®æ˜¾ç¤º */}
            <div className="flex-1 space-y-4">
              {emotionData.map((emotion) => (
                <div key={emotion.emotion} className="space-y-2">
                  <div className="flex justify-between items-center">
                    <span className="text-sm font-medium">{emotion.emotion}</span>
                    <span className="text-sm" style={{ color: emotion.color }}>
                      {emotion.percentage.toFixed(1)}%
                    </span>
                  </div>
                  <div className="w-full rounded-full h-3 overflow-hidden bg-[hsl(var(--muted))]">
                    <div
                      className="h-3 rounded-full transition-all duration-1000 ease-out"
                      style={{
                        width: `${emotion.percentage}%`,
                        backgroundColor: emotion.color,
                        boxShadow: `0 0 10px ${emotion.color}50`,
                      }}
                    />
                  </div>
                </div>
              ))}
            </div>

            {/* æƒ…æ„Ÿé›·è¾¾å›¾ */}
            <div className="mt-6 h-48 border rounded-lg flex items-center justify-center transition-colors duration-300 border-[hsl(var(--emoscan-border)/0.3)] bg-[hsl(var(--emoscan-bg)/0.8)]">
              <div className="relative w-32 h-32">
                {/* é›·è¾¾å›¾èƒŒæ™¯ */}
                <svg className="w-full h-full" viewBox="0 0 100 100">
                  {/* åŒå¿ƒåœ† */}
                  {[20, 40, 60, 80].map((r) => (
                    <circle
                      key={r}
                      cx="50"
                      cy="50"
                      r={r / 2}
                      fill="none"
                      stroke={isDark ? "hsl(142 76% 36% / 0.3)" : "hsl(220 13% 69% / 0.3)"}
                      strokeWidth="0.5"
                    />
                  ))}
                  {/* å°„çº¿ */}
                  {emotionData.map((_, i) => {
                    const angle = (i * (360 / emotionData.length) - 90) * (Math.PI / 180)
                    const x = 50 + 40 * Math.cos(angle)
                    const y = 50 + 40 * Math.sin(angle)
                    return (
                      <line key={i} x1="50" y1="50" x2={x} y2={y} stroke={isDark ? "hsl(142 76% 36% / 0.3)" : "hsl(220 13% 69% / 0.3)"} strokeWidth="0.5" />
                    )
                  })}
                  {/* æ•°æ®å¤šè¾¹å½¢ */}
                  <polygon
                    points={emotionData
                      .map((emotion, i) => {
                        const angle = (i * (360 / emotionData.length) - 90) * (Math.PI / 180)
                        const radius = (emotion.percentage / 100) * 35
                        const x = 50 + radius * Math.cos(angle)
                        const y = 50 + radius * Math.sin(angle)
                        return `${x},${y}`
                      })
                      .join(" ")}
                    fill={isDark ? "hsl(142 76% 36% / 0.2)" : "hsl(217 91% 60% / 0.2)"}
                    stroke={isDark ? "hsl(142 76% 36%)" : "hsl(217 91% 60%)"}
                    strokeWidth="1"
                  />
                </svg>
              </div>
            </div>
          </div>
        </div>

        {/* å³ä¾§é¢æ¿ - LLMè¾“å‡º */}
        <div className="w-1/3 backdrop-blur-sm p-6 transition-colors duration-300 bg-[hsl(var(--emoscan-panel)/0.5)]">
          <div className="h-full flex flex-col">
            <div className="flex justify-between items-center mb-4">
              <h2 className="text-lg font-semibold text-[hsl(var(--emoscan-accent))]">AI ANALYSIS OUTPUT</h2>
            </div>

            {/* LLMè¾“å‡ºæ˜¾ç¤º */}
              <div
                ref={outputRef}
                className="flex-1 border rounded-lg overflow-y-auto overflow-x-hidden ai-output-container relative transition-colors duration-300 border-[hsl(var(--emoscan-border)/0.3)] bg-[hsl(var(--emoscan-bg)/0.8)]"
                style={{
                  scrollbarWidth: 'none',
                  msOverflowStyle: 'none',
                } as React.CSSProperties}
              >
                {/* è¾¹ç¼˜æ¸å˜é®ç½©å±‚ - ä½¿ç”¨CSSå˜é‡è‡ªåŠ¨é€‚é…ä¸»é¢˜ */}
                <div
                  className="absolute inset-0 pointer-events-none z-10"
                  style={{
                    background: `linear-gradient(
                      to bottom,
                      rgba(var(--emoscan-gradient-color), 0.6) 0%,
                      rgba(var(--emoscan-gradient-color), 0.3) 8%,
                      rgba(var(--emoscan-gradient-color), 0.1) 20%,
                      transparent 30%,
                      transparent 70%,
                      rgba(var(--emoscan-gradient-color), 0.1) 80%,
                      rgba(var(--emoscan-gradient-color), 0.3) 92%,
                      rgba(var(--emoscan-gradient-color), 0.6) 100%
                    )`,
                    borderRadius: 'inherit',
                  }}
                />
                {/* 3Dåœ†æŸ±ä½“é€è§†æ–‡å­—å®¹å™¨ */}
                <div
                  className="relative cylindrical-text-container"
                  style={{
                    minHeight: '100%',
                    padding: '40px 16px', // å¢åŠ ä¸Šä¸‹å†…è¾¹è·ï¼Œç¡®ä¿é¡¶éƒ¨å’Œåº•éƒ¨æ–‡å­—æœ‰è¶³å¤Ÿç©ºé—´
                    textAlign: 'center', // æ‰€æœ‰æ–‡å­—å±…ä¸­å¯¹é½
                    height: 'auto', // å…è®¸å†…å®¹æ’‘å¼€é«˜åº¦
                  }}
                >
                  <div
                    className="cylindrical-text-display"
                    style={{
                      margin: 0,
                      padding: 0,
                      lineHeight: '1.8',
                    } as React.CSSProperties}
                  >
                    {(displayText || "Awaiting analysis data...").split('\n').map((line, index) => (
                      <div
                        key={index}
                        className="text-line"
                        style={{
                          marginBottom: '0.2em',
                        }}
                      >
                        {line || '\u00A0'} {/* ä½¿ç”¨éæ–­è¡Œç©ºæ ¼ä¿æŒç©ºè¡Œ */}
                      </div>
                    ))}
                  </div>

                  {/* å…‰æ ‡ */}
                  {(isTyping || (showCursor && displayText)) && (
                    <span
                      className={`inline-block w-1 h-4 ml-1 bg-[hsl(var(--emoscan-text))] ${
                        showCursor ? 'opacity-100' : 'opacity-0'
                      } transition-opacity duration-300`}
                      style={{
                        fontSize: '14px', // å…‰æ ‡å§‹ç»ˆä¿æŒä¸­å¿ƒå¤§å°
                      }}
                    >
                      |
                    </span>
                  )}
                </div>
              </div>
          </div>
        </div>
      </div>
    </div>
  )
}
